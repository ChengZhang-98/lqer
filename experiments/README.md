# References

* [All results in the paper](./LQER-icml2024.xlsx)
  * [Editable version (access permission required)](https://docs.google.com/spreadsheets/d/13CLlhnEDOJCDIvHw9luwo_wrXVPppr_p3sjjsmxpnMo/edit?usp=sharing)
* [lm-eval-harness FP16 model results](https://github.com/EleutherAI/lm-evaluation-harness/tree/25dfd3f6697edd7fbefc10dcb858337ed742910d/results)
* [AutoGPTQ](https://github.com/AutoGPTQ/AutoGPTQ) and AutoGPTQ OPT checkpoints on HuggingFace
* [LLM quantization baselines available on HuggingFace](https://huggingface.co/docs/transformers/v4.35.2/main_classes/quantization) and users ([TheBloke](https://huggingface.co/TheBloke), [casperhansen](https://huggingface.co/casperhansen)) who uploaded quantized checkpoints to HF.
  * LLM.int8()
  * GPTQ
  * AWQ
* [Another library to evaluate on MMLU](https://github.com/declare-lab/instruct-eval)
